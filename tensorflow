<02-Simple Linear Regression LAB>

import tensorflow as tf    #tensorflow를 불러와 실행. tf로 지정
import numpy as np    #numpy를 불러와 실행. np로 지정
tf.enable_eager_execution()    #eager execution을 기반한다는 것을 선언. 즉시 실행

# Data
x_data = [1, 2, 3, 4, 5]    #x 데이터를 불러옴
y_data = [1, 2, 3, 4, 5]    #y 데이터를 불러옴

# W, b initialize
W = tf.Variable(2.9)    #W에 임의의 값(2.9) 지정
b = tf.Variable(0.5)    #b에 임의의 값(0.5) 지정

learning_rate = 0.01    #학습 속도로 learning rate 값을 0.01로 지정

#W, b update 
for i in range(100+1):    #학습을 100번 수행    
    # Gradient descent
    with tf.GradientTape() as tape:    #경사하강법  gradient descent 사용
        hypothesis = W * x_data + b    #가설
        cost = tf.reduce_mean(tf.square(hypothesis - y_data))    #가설 값과 실제 값 차이의 평균으로 cost값을 지정
    W_grad, b_grad = tape.gradient(cost, [W, b])    #경사하강법은 이용한 cost값을 W_grad, b_grad로 지정
    W.assign_sub(learning_rate * W_grad)    #W값 할당(뺀 값)
    b.assign_sub(learning_rate * b_grad)    #b값 할당
    if i % 10 == 0:    
        print("{:5}|{:10.4f}|{:10.4}|{:10.6f}".format(i, W.numpy(), b.numpy(), cost))
        #i 값이 10의 배수가 될 때마다 출력(W,b의 값 변화를 확인)
print()  
#   i         w         b       cost
    0|    2.4520|    0.3760| 45.660004
   10|    1.1036|    0.0034|  0.206336
   20|    1.0128|   -0.0209|  0.001026
   30|    1.0065|   -0.0218|  0.000093
   40|    1.0059|   -0.0212|  0.000083
   50|    1.0057|   -0.0205|  0.000077
   60|    1.0055|   -0.0198|  0.000072
   70|    1.0053|   -0.0192|  0.000067
   80|    1.0051|   -0.0185|  0.000063
   90|    1.0050|   -0.0179|  0.000059
#W 값이 1.0으로 수렴
#b 값이 0으로 수렴
#cost 값이 0으로 수렴


<03-Liner Regression and How to minimize cost LAB>

#Cost function in pure Python    #cost 함수를 python으로 구현
import numpy as np    #numpy를 np로 지정

#data
X = np.array([1, 2, 3])    #x값 지정(입력값)
Y = np.array([1, 2, 3])    #y값 지정(출력값)
X와Y의 값을 같도록 만듦

def cost_func(W, X, Y):    #cost함수를 정의
    c = 0    #c값을 0으로 초기화
    for i in range(len(X)):     #X데이터 개수 만큼 반복
        c += (W * X[i] - Y[i]) ** 2    #cost값을 제곱한 후 c에 누적 덧셈 저장
    return c / len(X)    #X로 c를 나눔. 평균을 구함

for feed_W in np.linspace(-3, 5, num=15):    #linspace함수로 np의 시작과 끝을 지정. -3에서 5까지 15개의 구간으로 나누나눔
    curr_cost = cost_func(feed_W, X, Y)  # feed_W값에 따라 바뀌는 cost 값의 변화를 출력
    print("{:6.3f} | {:10.5f}".format(feed_W, curr_cost)) #출력

# Gradient descent
tf.set_random_seed(0) #for reproducibility    #random_seed를 초기화. 다음 실행시에도 동일하게 실행되도록 함

x_data = [1., 2., 3., 4.]    #x값 지정
y_data = [1., 3., 5., 7.]    #y값 지정

W = tf.Variable(tf.random_normal([1], -100., 100.))    #정규분포를 따르는 random수를 1로 변수를 만들어 W에 지정

for step in range(300):     #300회 수행
    hypothesis = W * X      #가설 설정
    cost = tf.reduce_mean(tf.square(hypothesis - Y))    #가설 값과 실제 값의 차이에 x를 곱하고 평균을 냄
    alpha = 0.01   #0.01로 상수 값 지정
    gradient = tf.reduce_mean(tf.multiply(tf.multiply(W, X) - Y, X))  # (W, X)-Y에 X를 곱한 것으로 평균을 구함
    descent = W - tf.multiply(alpha, gradient) #w값과 gradient를 구해서 alpa값을 곱하고 w에서 뺌
    W.assign(descent) #새로운 W값을 할당

    if step % 10 == 0: #10번에 한번씩 cost값과 W값을 확인
        print('{:5} | {:10.4f} | {:10.6f}'.format(
            step, cost.numpy(), W.numpy()[0]))
  #결과
    0 | 11716.3086 |  48.767971
   10 |  4504.9126 |  30.619968
   20 |  1732.1364 |  19.366755
   30 |   666.0052 |  12.388859
   40 |   256.0785 |   8.062004
   50 |    98.4620 |   5.379007
   60 |    37.8586 |   3.715335
   70 |    14.5566 |   2.683725
   80 |     5.5970 |   2.044044
   90 |     2.1520 |   1.647391
  100 |     0.8275 |   1.401434
  110 |     0.3182 |   1.248922
  120 |     0.1223 |   1.154351
  130 |     0.0470 |   1.095710
  140 |     0.0181 |   1.059348
  150 |     0.0070 |   1.036801
  160 |     0.0027 |   1.022819
  170 |     0.0010 |   1.014150
  180 |     0.0004 |   1.008774
  190 |     0.0002 |   1.005441
  200 |     0.0001 |   1.003374
  210 |     0.0000 |   1.002092
  220 |     0.0000 |   1.001297
  230 |     0.0000 |   1.000804
  240 |     0.0000 |   1.000499
  250 |     0.0000 |   1.000309
  260 |     0.0000 |   1.000192
  270 |     0.0000 |   1.000119
  280 |     0.0000 |   1.000074
  290 |     0.0000 |   1.000046




<04-Multi-variable linear regression LAB>
import tensorflow as tf    #tensorflow를 불러와 실행. tf로 지정
import numpy as np    #numpy를 불러와 실행. np로 지정
tf.enable_eager_execution()    #eager execution을 기반한다는 것을 선언. 즉시 실행

tf.set_random_seed(0)  # for reproducibility    #random_seed 초기화

# data and label # X data와 Y값 지정
x1 = [ 73., 93., 89., 96., 73.]
x2 = [ 80., 88., 91., 98., 66.]
x3 = [ 75., 93., 90., 100., 70.]
Y = [152., 185., 180., 196., 142.]

# random weights #변수의 개수만큼 3개의 w값을 만들고 초기값 1로 설정
w1 = tf.Variable(tf.random_normal([1]))
w2 = tf.Variable(tf.random_normal([1]))
w3 = tf.Variable(tf.random_normal([1]))
b = tf.Variable(tf.random_normal([1]))

learning_rate = 0.000001 #learnig rate값 지정

for i in range(1000+1): # 1001회 수행
    # tf.GradientTape() to record the gradient of the cost function
    with tf.GradientTape() as tape: # 아래의 변수들을 gradientTape에 저장
        hypothesis = w1 * x1 + w2 * x2 + w3 * x3 + b #가설 정의
        cost = tf.reduce_mean(tf.square(hypothesis - Y)) # cost 정의
    # calculates the gradients of the cost
    w1_grad, w2_grad, w3_grad, b_grad = tape.gradient(cost, [w1, w2, w3, b])
    #변수들을 tape에 호출해서 기울기를 gradient값에 할당
    # update w1,w2,w3 and b
    w1.assign_sub(learning_rate * w1_grad)
    w2.assign_sub(learning_rate * w2_grad)
    w3.assign_sub(learning_rate * w3_grad)
    b.assign_sub(learning_rate * b_grad)
    #각각의 값을 w1,w2,w3에 업데이트. 할당한 값에 learning rate 곱해서 업데이트

    if i % 50 == 0: #50번마다 cost값 출력
    print("{:5} | {:12.4f}".format(i, cost.numpy()))
#결과
    0 |   11325.9121
   50 |     135.3618    
  100 |      11.1817
  150 |       9.7940
  200 |       9.7687
  250 |       9.7587
  300 |       9.7489
  350 |       9.7389
  400 |       9.7292
  450 |       9.7194
  500 |       9.7096
  550 |       9.6999
  600 |       9.6903
  650 |       9.6806
  700 |       9.6709
  750 |       9.6612
  800 |       9.6517
  850 |       9.6421
  900 |       9.6325
  950 |       9.6229
 1000 |       9.6134
 #일정 순간부터 cost 값이 일정

# Matrix    #데이터를 간결하게 표현
data = np.array([
    # X1, X2, X3, y
    [ 73., 80., 75., 152. ],
    [ 93., 88., 93., 185. ],
    [ 89., 91., 90., 180. ],
    [ 96., 98., 100., 196. ],
    [ 73., 66., 70., 142. ]
], dtype=np.float32)

# slice data
X = data[:, :-1] # 위 데이터의 전체 행과 마지막 열을 제외한 5행 3열의 데이터
y = data[:, [-1]] #y값 지정.마지막 열

W = tf.Variable(tf.random_normal([3, 1]))
b = tf.Variable(tf.random_normal([1]))
# X열 3개이므로 W의 값도 3개. 출력 값 1개로 지정


learning_rate = 0.000001 #learning rate 지정

# hypothesis, prediction function
def predict(X): #예측함수 지정
    return tf.matmul(X, W) + b

n_epochs = 2000    #2001번 epoch 반복
for i in range(n_epochs+1): 
    # record the gradient of the cost function
    with tf.GradientTape() as tape: # cost를 Tape에 저장
        cost = tf.reduce_mean((tf.square(predict(X) - y)))    #cost함수 정의

    # calculates the gradients of the loss
    W_grad, b_grad = tape.gradient(cost, [W, b]) #tape을 불러내어 변수 할당

    # updates parameters (W and b)    #learning_rate값과 grade 값을 곱한 값을 빼서 할당
    W.assign_sub(learning_rate * W_grad)
    b.assign_sub(learning_rate * b_grad)

    if i % 100 == 0:     #100번에 한번 cost값 출력
       print("{:5} | {:10.4f}".format(i, cost.numpy()))
# 결과
epoch | cost
    0 |  5455.5903      
  100 |    31.7443
  200 |    30.9326
  300 |    30.7894
  400 |    30.6468
  500 |    30.5055
  600 |    30.3644
  700 |    30.2242
  800 |    30.0849
  900 |    29.9463
 1000 |    29.8081
 1100 |    29.6710
 1200 |    29.5348
 1300 |    29.3989
 1400 |    29.2641
 1500 |    29.1299
 1600 |    28.9961
 1700 |    28.8634
 1800 |    28.7313
 1900 |    28.5997
 2000 |    28.4689



<05-2-logistic_regression>
import tensorflow.contrib.eager as tfe    #tensorflow를 실행하기 위해 기본적인 library를 import
tf.enable_eager_execution()    #eager execution을 기반한다는 것을 선언. 즉시 실행
dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(len(x_train))
#tf data를 통해서 x값과 y값을 실제 x의 길이 만큼 뱃치로 학습
W = tf.Variable(tf.zeros([2,1]), name='weight')  #2행 1열의 값
b = tf.Variable(tf.zeros([1]), name='bias')

def logistic_regression(features):     #logistic regrettion정의
    hypothesis = tf.div(1., 1. + tf.exp(tf.matmul(features, W) + b))    #sigmoid함수를 사용하여 가설 설정
    return hypothesis    #logistic regreession에 대한 가설을 그려냄
def loss_fn(hypothesis, labels): #가설로 나온 값은 label 값을 통해 코스트 값 구현
    cost = -tf.reduce_mean(labels * tf.log(loss_fn(hypothesis) + (1 - labels) * tf.log(1 - hypothesis))
    return cost
    #실제 코스트값 할당
def grad(hypothesis, features, labels): # 가설과 label을 통해 나온 loss값 선언
    with tf.GradientTape() as tape:
        loss_value = loss_fn(hypothesis,labels)
    return tape.gradient(loss_value, [W,b]) #gradient를 통해 지속적으로 값을 바꿈
optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)

for step in range(EPOCHS): #epoch만큼 반복
for features, labels in tfe.Iterator(dataset):    #x 값과 y값을 iterator를 돌려서 넣음
grads = grad(logistic_regression(features), features, labels)
optimizer.apply_gradients(grads_and_vars=zip(grads,[W,b])) #cost값 최소화
if step % 100 == 0: #100번에 한번 출력 step과 loss, label값
print("Iter: {}, Loss: {:.4f}".format(step, loss_fn(logistic_regression(features) ,labels)))

def accuracy_fn(hypothesis, labels): #가설과 실제값 비교
predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32) #예측한 값
accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.int32))
return accuracy  #accuracy로 출력
test_acc = accuracy_fn(logistic_regression(x_test),y_test)
print("Test Accuracy: {:4f}", format(test_acc))

#결과
Iter: 0, Loss: 0.6874
Iter: 100, Loss: 0.5776 
Iter: 200, Loss: 0.5349
Iter: 300, Loss: 0.5054
Iter: 400, Loss: 0.4838
Iter: 500, Loss: 0.4671
Iter: 600, Loss: 0.4535
Iter: 700, Loss: 0.4420
Iter: 800, Loss: 0.4319
Iter: 900, Loss: 0.4228
Iter: 1000, Loss: 0.4144
Testset Accuracy: 1.0000 
